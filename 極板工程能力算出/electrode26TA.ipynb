{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe9d6a65-e027-4f1e-92fd-7dd634a53bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from datetime import date,timedelta\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import glob\n",
    "import re\n",
    "import cx_Oracle as oracle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c5fb6e-a065-41b7-8f50-71b843e1d2fd",
   "metadata": {},
   "source": [
    "### DB書き込み用のクラスを定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae2890dd-710c-4e55-9c07-d1ed7e6dda01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CX oracleでMESサーバーへ接続（接続情報以外は定型）\n",
    "class conn_MES_LWR:\n",
    "    def __init__(self, host= \"10.60.28.21\", port=\"1521\", service=\"psh1dbv\",\n",
    "                       scheme=\"tabuser\",username=\"tabuser\",password=\"tab123\"):        \n",
    "        self.host = host\n",
    "        self.port = port\n",
    "        self.service  = service\n",
    "\n",
    "        self.scheme   = scheme\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "    \n",
    "    def __enter__(self):\n",
    "        \n",
    "        # tns:Oracleが命名したDB接続用インターフェース技術の名前\n",
    "        \n",
    "        # インターフェイスオブジェクトの作成\n",
    "        self.tns  = oracle.makedsn(self.host, self.port, service_name=self.service) if self.host else None\n",
    "        # 接続を確立\n",
    "        self.conn = oracle.connect(self.username, self.password, self.tns) if self.tns else None\n",
    "        # カーソルの取得\n",
    "        self.curs = self.conn.cursor() if self.conn else None\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exception_type, exception_value, traceback):\n",
    "        if self.curs is not None: self.curs.close()\n",
    "        if self.conn is not None: self.conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2c1ac6-b5d0-463a-bb27-595b9c3aa23f",
   "metadata": {},
   "source": [
    "### DB書き込み用の関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9228252d-9ee1-4f05-8c53-eeeadb4c63fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_data(insert_sql=None, df=None):\n",
    "    \n",
    "    # DBに格納できるようにデータフレームを二次元配列に変換\n",
    "    rows = [list(x) for x in df.values]\n",
    "    \n",
    "    with conn_MES_LWR() as mesdb:\n",
    "        # executemany()で複数行のデータを一括でインサート\n",
    "        mesdb.curs.executemany(insert_sql, rows)\n",
    "        mesdb.conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f50b885-37cf-40e7-86e1-787d3130b88d",
   "metadata": {},
   "source": [
    "### DBアップロード用のSQLを定義"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd3f3e1-0ac7-43bd-b207-6e9b6288efd8",
   "metadata": {},
   "source": [
    "##### 170m以上用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff32f955-b163-482a-ba77-a0dec6e30427",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_data_sql = '''\n",
    "    INSERT INTO \"TABUSER\".\"Electrode26TA\" \n",
    "    (\n",
    "        \"ProductionDate\", \n",
    "        \"LotNo\", \n",
    "        \"Sides\", \n",
    "        \"S/E\", \n",
    "        \"ActualThickness(WS)\", \n",
    "        \"ActualThickness(CS)\", \n",
    "        \"ActualThickness(DS)\", \n",
    "        \"FoilWeight(DS)\", \n",
    "        \"CoatingWight(DS)\", \n",
    "        \"CoatingWight(WS)\", \n",
    "        \"SampleWeight(DS)\",\n",
    "        \"SampleWeight(WS)\", \n",
    "        \"FillingDensity(DS)\", \n",
    "        \"FillingDensity(WS)\", \n",
    "        \"ElectrodeWidth(withTab)(DS)\", \n",
    "        \"ElectrodeWidth(withoutTab)(DS)\", \n",
    "        \"TabWidth1(DS)\", \n",
    "        \"Pitch(DS)\", \n",
    "        \"TabR1(convex)(DS)\",\n",
    "        \"TabR2(convex)(DS)\", \n",
    "        \"TabR1(concave)(DS)\", \n",
    "        \"TabR2(concave)(DS)\", \n",
    "        \"CoatingWidth(withoutProtectiveLayer)(Surface)(DS)\",\n",
    "        \"CoatingWidth(withProtectiveLayer)(Surface)(DS)\", \n",
    "        \"CoatingWidth(withoutProtectiveLayer)(Back)(DS)\",\n",
    "        \"CoatingWidth(withProtectiveLayer)(Back)(DS)\", \n",
    "        \"HorizontalBurr(Slit)(DS)\", \n",
    "        \"VirticalBurr(Slit)(DS)\",\n",
    "        \"HorizontalBurr(Tab)(DS)\", \n",
    "        \"VirticalBurr(Tab)(DS)\", \n",
    "        \"HorizontalBurr(ProtectiveLayer)(DS)\", \n",
    "        \"VirticalBurr(ProtectiveLayer)(DS)\", \n",
    "        \"HigeBurr(DS)\", \n",
    "        \"ElectrodeWidth(withTab)(WS)\", \n",
    "        \"ElectrodeWidth(withoutTab)(WS)\", \n",
    "        \"TabWidth1(WS)\", \n",
    "        \"Pitch(WS)\", \n",
    "        \"TabR1(convex)(WS)\",\n",
    "        \"TabR2(convex)(WS)\", \n",
    "        \"TabR1(concave)(WS)\", \n",
    "        \"TabR2(concave)(WS)\", \n",
    "        \"CoatingWidth(withoutProtectiveLayer)(Surface)(WS)\",\n",
    "        \"CoatingWidth(withProtectiveLayer)(Surface)(WS)\",\n",
    "        \"CoatingWidth(withoutProtectiveLayer)(Back)(WS)\",\n",
    "        \"CoatingWidth(withProtectiveLayer)(Back)(WS)\", \n",
    "        \"HorizontalBurr(Slit)(WS)\", \n",
    "        \"VirticalBurr(Slit)(WS)\",\n",
    "        \"HorizontalBurr(Tab)(WS)\", \n",
    "        \"VirticalBurr(Tab)(WS)\",\n",
    "        \"HorizontalBurr(ProtectiveLayer)(WS)\", \n",
    "        \"VirticalBurr(ProtectiveLayer)(WS)\", \n",
    "        \"HigeBurr(WS)\",\n",
    "        \"WindSpeed(Upper)(WS)\", \n",
    "        \"WindSpeed(Upper)(DS)\", \n",
    "        \"WindSpeed(Lower)(WS)\", \n",
    "        \"WindSpeed(Lower)(DS)\",\n",
    "        \"Twist(DS)\", \n",
    "        \"Twist(WS)\", \n",
    "        \"Twist(AfterRewinding)(DS)\", \n",
    "        \"Twist(AfterRewinding)(WS)\" \n",
    "    ) \n",
    "    VALUES (:1,:2,:3,:4,:5,:6,:7,:8,:9,:10,:11,:12,:13,:14,:15,:16,:17,:18,:19,:20,\n",
    "            :21,:22,:23,:24,:25,:26,:27,:28,:29,:30,:31,:32,:33,:34,:35,:36,:37,:38,:39,:40,\n",
    "            :41,:42,:43,:44,:45,:46,:47,:48,:49,:50,:51,:52,:53,:54,:55,:56,:57,:58,:59,:60)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0648a513-5c6d-4444-9fad-a10ba178fae1",
   "metadata": {},
   "source": [
    "##### 170m未満用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c170dcda-76bb-426b-855e-e6758ed6df6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_data_sql_lt170 = '''\n",
    "    INSERT INTO \"TABUSER\".\"Electrode26TAlt170\" \n",
    "    (\n",
    "        \"ProductionDate\", \n",
    "        \"LotNo\", \n",
    "        \"Sides\", \n",
    "        \"S/E\", \n",
    "        \"ActualThickness(WS)\", \n",
    "        \"ActualThickness(CS)\", \n",
    "        \"ActualThickness(DS)\", \n",
    "        \"FoilWeight(DS)\", \n",
    "        \"CoatingWight(DS)\", \n",
    "        \"CoatingWight(WS)\", \n",
    "        \"SampleWeight(DS)\",\n",
    "        \"SampleWeight(WS)\", \n",
    "        \"FillingDensity(DS)\", \n",
    "        \"FillingDensity(WS)\", \n",
    "        \"ElectrodeWidth(withTab)(DS)\", \n",
    "        \"ElectrodeWidth(withoutTab)(DS)\", \n",
    "        \"TabWidth1(DS)\", \n",
    "        \"Pitch(DS)\", \n",
    "        \"TabR1(convex)(DS)\",\n",
    "        \"TabR2(convex)(DS)\", \n",
    "        \"TabR1(concave)(DS)\", \n",
    "        \"TabR2(concave)(DS)\", \n",
    "        \"CoatingWidth(withoutProtectiveLayer)(Surface)(DS)\",\n",
    "        \"CoatingWidth(withProtectiveLayer)(Surface)(DS)\", \n",
    "        \"CoatingWidth(withoutProtectiveLayer)(Back)(DS)\",\n",
    "        \"CoatingWidth(withProtectiveLayer)(Back)(DS)\", \n",
    "        \"HorizontalBurr(Slit)(DS)\", \n",
    "        \"VirticalBurr(Slit)(DS)\",\n",
    "        \"HorizontalBurr(Tab)(DS)\", \n",
    "        \"VirticalBurr(Tab)(DS)\", \n",
    "        \"HorizontalBurr(ProtectiveLayer)(DS)\", \n",
    "        \"VirticalBurr(ProtectiveLayer)(DS)\", \n",
    "        \"HigeBurr(DS)\", \n",
    "        \"ElectrodeWidth(withTab)(WS)\", \n",
    "        \"ElectrodeWidth(withoutTab)(WS)\", \n",
    "        \"TabWidth1(WS)\", \n",
    "        \"Pitch(WS)\", \n",
    "        \"TabR1(convex)(WS)\",\n",
    "        \"TabR2(convex)(WS)\", \n",
    "        \"TabR1(concave)(WS)\", \n",
    "        \"TabR2(concave)(WS)\", \n",
    "        \"CoatingWidth(withoutProtectiveLayer)(Surface)(WS)\",\n",
    "        \"CoatingWidth(withProtectiveLayer)(Surface)(WS)\",\n",
    "        \"CoatingWidth(withoutProtectiveLayer)(Back)(WS)\",\n",
    "        \"CoatingWidth(withProtectiveLayer)(Back)(WS)\", \n",
    "        \"HorizontalBurr(Slit)(WS)\", \n",
    "        \"VirticalBurr(Slit)(WS)\",\n",
    "        \"HorizontalBurr(Tab)(WS)\", \n",
    "        \"VirticalBurr(Tab)(WS)\",\n",
    "        \"HorizontalBurr(ProtectiveLayer)(WS)\", \n",
    "        \"VirticalBurr(ProtectiveLayer)(WS)\", \n",
    "        \"HigeBurr(WS)\",\n",
    "        \"WindSpeed(Upper)(WS)\", \n",
    "        \"WindSpeed(Upper)(DS)\", \n",
    "        \"WindSpeed(Lower)(WS)\", \n",
    "        \"WindSpeed(Lower)(DS)\",\n",
    "        \"Twist(DS)\", \n",
    "        \"Twist(WS)\", \n",
    "        \"Twist(AfterRewinding)(DS)\", \n",
    "        \"Twist(AfterRewinding)(WS)\" \n",
    "    ) \n",
    "    VALUES (:1,:2,:3,:4,:5,:6,:7,:8,:9,:10,:11,:12,:13,:14,:15,:16,:17,:18,:19,:20,\n",
    "            :21,:22,:23,:24,:25,:26,:27,:28,:29,:30,:31,:32,:33,:34,:35,:36,:37,:38,:39,:40,\n",
    "            :41,:42,:43,:44,:45,:46,:47,:48,:49,:50,:51,:52,:53,:54,:55,:56,:57,:58,:59,:60)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bb6794d-b1fe-459e-b5ea-7af215c17f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 今日の日付データを取得(年・月・日)\n",
    "year = datetime.date.today().year\n",
    "month = datetime.date.today().month\n",
    "day = datetime.date.today().day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43d4e291-0926-4f1d-895f-89a041aa95ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各ファイルの最終行を記録したdictをデシリアライズ(前月分)\n",
    "with open('row_num_last_month.pickle', 'rb') as f:\n",
    "    dict_for_last_month = pickle.load(f)  \n",
    "\n",
    "# 各ファイルの最終行を記録したdictをデシリアライズ(今月分)\n",
    "with open('row_num_this_month.pickle', 'rb') as f:\n",
    "    dict_for_this_month = pickle.load(f)  \n",
    "\n",
    "# 各ファイルの最終行を記録したdictをデシリアライズ(前月分, 170m未満)\n",
    "with open('row_num_lt170_last_month.pickle', 'rb') as f:\n",
    "    dict_for_last_month_lt170 = pickle.load(f)  \n",
    "\n",
    "# 各ファイルの最終行を記録したdictをデシリアライズ(今月分, 170m未満)\n",
    "with open('row_num_lt170_this_month.pickle', 'rb') as f:\n",
    "    dict_for_this_month_lt170 = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15503d7d-426d-4b4d-954f-45ccd08c0b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 月替わりにはシリアライズするデータを初期化\n",
    "if day == 1:\n",
    "    # 前月分のpickleデータを変更(170m以上)\n",
    "    with open('row_num_last_month.pickle', 'wb') as f:\n",
    "        pickle.dump(dict_for_this_month, f)\n",
    "    dict_for_last_month = dict_for_this_month\n",
    "    # 前月分のpickleデータを変更(170m未満)\n",
    "    with open('row_num_lt170_last_month.pickle', 'wb') as f:\n",
    "        pickle.dump(dict_for_this_month_lt170, f)\n",
    "    dict_for_last_month_lt170 = dict_for_this_month_lt170\n",
    "    \n",
    "    \n",
    "    # 今月分のpickleデータを初期化(170m以上)\n",
    "    dict_for_this_month = {\"1-1\": None, \"1-2\": None, \"1-3-1\": None, \"1-3-2\": None, \"2-1\": None, \"2-2\": None}\n",
    "    # 今月分のpickleデータを初期化(170m以上)\n",
    "    dict_for_this_month_lt170 = {\"1-1\": None, \"1-2\": None, \"1-3-1\": None, \"1-3-2\": None, \"2-1\": None, \"2-2\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a797432-0224-47c3-b298-441b43c734ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 検索対象フォルダのパスを設定し、ファイルを取得\n",
    "cwd = os.getcwd()\n",
    "line_folder = [\"1期\", \"2期\", \"3号機\"]\n",
    "target_date_folder = str(year) + \"年\" + str(month) + \"月\"\n",
    "\n",
    "data_files_last_month = []\n",
    "data_files_this_month = []\n",
    "\n",
    "# 毎月10日までは前月分のファイルも覗きにいく\n",
    "if day <= 10:\n",
    "    \n",
    "    # 1月度の場合は昨年の12月度のフォルダを見に行く\n",
    "    if month == 1:\n",
    "        target_date_folder2 = str(year - 1) + \"年\" + str(12) + \"月\"\n",
    "    # それ以外の場合は前月度のフォルダを見に行く\n",
    "    else:    \n",
    "        target_date_folder2 = str(year) + \"年\" + str(month - 1) + \"月\"\n",
    "        \n",
    "    for each_line in line_folder:\n",
    "        \n",
    "        file_path1 = cwd + \"\\\\★20200701_正極圧縮管理図\\\\\" + each_line + \"\\\\\" + target_date_folder2 + \"\\\\*\" \n",
    "        file_path2 = cwd + \"\\\\★20200701_正極圧縮管理図\\\\\" + each_line + \"\\\\\" + target_date_folder2 + \"\\\\\"\n",
    "\n",
    "        for f in glob.glob(file_path1):\n",
    "            file_name = os.path.split(f)[1]\n",
    "            if re.findall(\"\\d{4}\\.\\d{2}_\", file_name):\n",
    "\n",
    "                data_files_last_month.append(file_path2 + file_name)\n",
    "            \n",
    "            \n",
    "\n",
    "for each_line in line_folder:\n",
    "    \n",
    "    file_path1 = cwd + \"\\\\★20200701_正極圧縮管理図\\\\\" + each_line + \"\\\\\" + target_date_folder + \"\\\\*\" \n",
    "    file_path2 = cwd + \"\\\\★20200701_正極圧縮管理図\\\\\" + each_line + \"\\\\\" + target_date_folder + \"\\\\\"\n",
    "    \n",
    "    for f in glob.glob(file_path1):\n",
    "        file_name = os.path.split(f)[1]\n",
    "        if re.findall(\"\\d{4}\\.\\d{2}_\", file_name):\n",
    "\n",
    "            data_files_this_month.append(file_path2 + file_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b47251fe-d0bb-472e-bf61-6e6ab1c937ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DFのヘッダを作成\n",
    "s = \"\"\"ProductionDate\n",
    "dummy\n",
    "LotNo\n",
    "Sides\n",
    "S/E\n",
    "ActualThickness(WS)\n",
    "ActualThickness(CS)\n",
    "ActualThickness(DS)\n",
    "FoilWeight(DS)\n",
    "CoatingWight(DS)\n",
    "CoatingWight(WS)\n",
    "SampleWeight(DS)\n",
    "SampleWeight(WS)\n",
    "FillingDensity(DS)\n",
    "FillingDensity(WS)\n",
    "ElectrodeWidth(withTab)(DS)\n",
    "ElectrodeWidth(withoutTab)(DS)\n",
    "TabWidth1(DS)\n",
    "Pitch(DS)\n",
    "TabR1(convex)(DS)\n",
    "TabR2(convex)(DS)\n",
    "TabR1(concave)(DS)\n",
    "TabR2(concave)(DS)\n",
    "CoatingWidth(withoutProtectiveLayer)(Surface)(DS)\n",
    "CoatingWidth(withProtectiveLayer)(Surface)(DS)\n",
    "CoatingWidth(withoutProtectiveLayer)(Back)(DS)\n",
    "CoatingWidth(withProtectiveLayer)(Back)(DS)\n",
    "HorizontalBurr(Slit)(DS)\n",
    "VirticalBurr(Slit)(DS)\n",
    "HorizontalBurr(Tab)(DS)\n",
    "VirticalBurr(Tab)(DS)\n",
    "HorizontalBurr(ProtectiveLayer)(DS)\n",
    "VirticalBurr(ProtectiveLayer)(DS)\n",
    "HigeBurr(DS)\n",
    "ElectrodeWidth(withTab)(WS)\n",
    "ElectrodeWidth(withoutTab)(WS)\n",
    "TabWidth1(WS)\n",
    "Pitch(WS)\n",
    "TabR1(convex)(WS)\n",
    "TabR2(convex)(WS)\n",
    "TabR1(concave)(WS)\n",
    "TabR2(concave)(WS)\n",
    "CoatingWidth(withoutProtectiveLayer)(Surface)(WS)\n",
    "CoatingWidth(withProtectiveLayer)(Surface)(WS)\n",
    "CoatingWidth(withoutProtectiveLayer)(Back)(WS)\n",
    "CoatingWidth(withProtectiveLayer)(Back)(WS)\n",
    "HorizontalBurr(Slit)(WS)\n",
    "VirticalBurr(Slit)(WS)\n",
    "HorizontalBurr(Tab)(WS)\n",
    "VirticalBurr(Tab)(WS)\n",
    "HorizontalBurr(ProtectiveLayer)(WS)\n",
    "VirticalBurr(ProtectiveLayer)(WS)\n",
    "HigeBurr(WS)\n",
    "WindSpeed(Upper)(WS)\n",
    "WindSpeed(Upper)(DS)\n",
    "WindSpeed(Lower)(WS)\n",
    "WindSpeed(Lower)(DS)\n",
    "Twist(DS)\n",
    "Twist(WS)\n",
    "Twist(AfterRewinding)(DS)\n",
    "Twist(AfterRewinding)(WS)\"\"\"\n",
    "\n",
    "# 文字列を列名のリストに変換\n",
    "df_header = s.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f63f2ad3-dd4b-482f-b7ad-f874a9ec0984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 170m以上のファイルと未満のファイルに振り分け\n",
    "\n",
    "# 前月分\n",
    "if data_files_last_month:\n",
    "    data_files_last_month_gt_170 = []\n",
    "    data_files_last_month_lt_170 = []\n",
    "\n",
    "    for file in data_files_last_month:\n",
    "        if \"以上\" in file:\n",
    "            data_files_last_month_gt_170.append(file)\n",
    "        elif \"未満\" in file:\n",
    "            data_files_last_month_lt_170.append(file)\n",
    "        \n",
    "\n",
    "# 今月分\n",
    "data_files_this_month_gt_170 = []\n",
    "data_files_this_month_lt_170 = []\n",
    "\n",
    "for file in data_files_this_month:\n",
    "    if \"以上\" in file:\n",
    "        data_files_this_month_gt_170.append(file)\n",
    "    elif \"未満\" in file:\n",
    "        data_files_this_month_lt_170.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc56c4bd-9ddc-4bf7-8629-4021c7e002e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# シート名のリストを作成\n",
    "sheet_name_1 = [\"1-1\", \"1-2\"]\n",
    "sheet_name_2 = [\"2-1\", \"2-2\"]\n",
    "sheet_name_3 = [\"1-3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884fcd4a-571b-4e5b-94f3-6d3a89492a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "478a1be1-0ed3-4284-9179-29c71d9de5d8",
   "metadata": {},
   "source": [
    "# 170万メートル以上のデータ処理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d57f9b-32d8-4232-863a-360c155c2c13",
   "metadata": {},
   "source": [
    "### 各ファイルのデータをDFに読み込む (前月分)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e587dabe-7d82-49fc-82d8-74cb4b275127",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "# 各ファイルのシート毎にDFを作成\n",
    "\n",
    "# '3号機'ファイル用にインデックスを準備\n",
    "idx_for_1_3 = 1\n",
    "for file in data_files_last_month_gt_170:\n",
    "    \n",
    "    if \"1期正極\" in file:\n",
    "        \n",
    "        # 行番号をシリアライズするためにenumerate()のインデックスを利用\n",
    "        for idx, sheet_name in enumerate(sheet_name_1, start=1):\n",
    "            df = pd.read_excel(file, sheet_name=sheet_name, names=df_header, header=12, usecols=range(0, 61))\n",
    "            # NaN -> 0\n",
    "            df.fillna(0, inplace=True)\n",
    "            # dummy列の削除\n",
    "            df.drop(['dummy'], axis=1, inplace=True)\n",
    "            # データのある行のみを抽出\n",
    "            df = df[df['ActualThickness(WS)'] != 0]\n",
    "            # 生産日のデータを日付に変換\n",
    "            df[\"ProductionDate\"] = df[\"ProductionDate\"].apply(get_datetime)\n",
    "            key_name = \"1-\" + str(idx)\n",
    "            # 今回読み込み時の最終行を取得\n",
    "            latest_last_row = df.shape[0]\n",
    "            # 前回時の最終行を読み込み\n",
    "            last_time_last_row = dict_for_last_month[key_name]\n",
    "            # 新たにデータが追加されていた場合のみdictの書き換えとDFの読み込みを行う\n",
    "            if latest_last_row != last_time_last_row:\n",
    "                dict_for_last_month[key_name] = latest_last_row\n",
    "                # 前回更新時の最終行から取得\n",
    "                df = df.iloc[last_time_last_row:, :]\n",
    "                df_list.append(df)\n",
    "    elif \"2期正極\" in file:\n",
    "        # 行番号をシリアライズするためにenumerate()のインデックスを利用\n",
    "        for idx, sheet_name in enumerate(sheet_name_2, start=1):\n",
    "            df = pd.read_excel(file, sheet_name=sheet_name, names=df_header, header=12, usecols=range(0, 61))\n",
    "            # NaN -> 0\n",
    "            df.fillna(0, inplace=True)\n",
    "            # dummy列の削除\n",
    "            df.drop(['dummy'], axis=1, inplace=True)\n",
    "            # データのある行のみを抽出\n",
    "            df = df[df['ActualThickness(WS)'] != 0]\n",
    "            # 生産日のデータを日付に変換\n",
    "            df[\"ProductionDate\"] = df[\"ProductionDate\"].apply(get_datetime)\n",
    "            key_name = \"2-\" + str(idx)\n",
    "            # 今回読み込み時の最終行を取得\n",
    "            latest_last_row = df.shape[0]\n",
    "            # 前回時の最終行を読み込み\n",
    "            last_time_last_row = dict_for_last_month[key_name]\n",
    "            # 新たにデータが追加されていた場合のみdictの書き換えとDFの読み込みを行う\n",
    "            if latest_last_row != last_time_last_row:\n",
    "                dict_for_last_month[key_name] = latest_last_row\n",
    "                # 前回更新時最終行から取得\n",
    "                df = df.iloc[last_time_last_row:, :]\n",
    "                df_list.append(df)\n",
    "    elif \"3号機\" in file:\n",
    "        df = pd.read_excel(file, sheet_name='1-3', names=df_header, header=12, usecols=range(0, 61))\n",
    "        # NaN -> 0\n",
    "        df.fillna(0, inplace=True)\n",
    "        # dummy列の削除\n",
    "        df.drop(['dummy'], axis=1, inplace=True)\n",
    "        # データのある行のみを抽出\n",
    "        df = df[df['ActualThickness(WS)'] != 0]\n",
    "        # 生産日のデータを日付に変換\n",
    "        df[\"ProductionDate\"] = df[\"ProductionDate\"].apply(get_datetime)\n",
    "        key_name = \"1-3-\" + str(idx_for_1_3)\n",
    "        # 今回読み込み時の最終行を取得\n",
    "        latest_last_row = df.shape[0]\n",
    "        # 前回時の最終行を読み込み\n",
    "        last_time_last_row = dict_for_last_month[key_name]\n",
    "        # 新たにデータが追加されていた場合のみdictの書き換えとDFの読み込みを行う\n",
    "        if latest_last_row != last_time_last_row:\n",
    "            dict_for_last_month[key_name] = latest_last_row\n",
    "            # 前回更新時最終行から取得\n",
    "            df = df.iloc[last_time_last_row:, :]\n",
    "            df_list.append(df)\n",
    "        idx_for_1_3 += 1\n",
    "        \n",
    "\n",
    "# 各ファイルの最終行を記録したdictをシリアライズ\n",
    "with open('row_num_last_month.pickle', 'wb') as f:\n",
    "    pickle.dump(dict_for_last_month, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4858f6-d19a-4c83-85ec-c1e7b249de85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 更新されたDFが1つだけの場合はそのまま取り出す\n",
    "if len(df_list) == 1:\n",
    "    df_upload = df_list[0]\n",
    "elif len(df_list) == 0:\n",
    "    df_uploat = None\n",
    "# 複数ある場合はUnion\n",
    "else:\n",
    "    df_upload = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5f8e702-c209-47c5-9ad9-ca63c09b800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBにデータをアップロード(前月分・170m以上)\n",
    "# 更新されたデータがあった場合のみDBにアップロード\n",
    "if len(df_upload):\n",
    "    upload_data(insert_data_sql, df_upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5d99ee-80f7-465d-99dd-a722b855fb4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a95d842-b559-4d04-bf26-df676415554e",
   "metadata": {},
   "source": [
    "### 各ファイルのデータをDFに読み込む (今月分)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e5cc73b-308f-4888-9cf4-b50c74fede5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "# 各ファイルのシート毎にDFを作成\n",
    "\n",
    "# '3号機'ファイル用にインデックスを準備\n",
    "idx_for_1_3 = 1\n",
    "for file in data_files_this_month_gt_170:\n",
    "    \n",
    "    if \"1期正極\" in file:\n",
    "        \n",
    "        # 行番号をシリアライズするためにenumerate()のインデックスを利用\n",
    "        for idx, sheet_name in enumerate(sheet_name_1, start=1):\n",
    "            df = pd.read_excel(file, sheet_name=sheet_name, names=df_header, header=12, usecols=range(0, 61))\n",
    "            # NaN -> 0\n",
    "            df.fillna(0, inplace=True)\n",
    "            # dummy列の削除\n",
    "            df.drop(['dummy'], axis=1, inplace=True)\n",
    "            # データのある行のみを抽出\n",
    "            df = df[df['ActualThickness(WS)'] != 0]\n",
    "            # 生産日のデータを日付に変換\n",
    "            df[\"ProductionDate\"] = df[\"ProductionDate\"].apply(get_datetime)\n",
    "            key_name = \"1-\" + str(idx)\n",
    "            # 今回読み込み時の最終行を取得\n",
    "            latest_last_row = df.shape[0]\n",
    "            # 前回時の最終行を読み込み\n",
    "            last_time_last_row = dict_for_this_month[key_name]\n",
    "            # 新たにデータが追加されていた場合のみdictの書き換えとDFの読み込みを行う\n",
    "            if latest_last_row != last_time_last_row:\n",
    "                dict_for_this_month[key_name] = latest_last_row\n",
    "                # 前回更新時の最終行から取得\n",
    "                df = df.iloc[last_time_last_row:, :]\n",
    "                df_list.append(df)\n",
    "    elif \"2期正極\" in file:\n",
    "        # 行番号をシリアライズするためにenumerate()のインデックスを利用\n",
    "        for idx, sheet_name in enumerate(sheet_name_2, start=1):\n",
    "            df = pd.read_excel(file, sheet_name=sheet_name, names=df_header, header=12, usecols=range(0, 61))\n",
    "            # NaN -> 0\n",
    "            df.fillna(0, inplace=True)\n",
    "            # dummy列の削除\n",
    "            df.drop(['dummy'], axis=1, inplace=True)\n",
    "            # データのある行のみを抽出\n",
    "            df = df[df['ActualThickness(WS)'] != 0]\n",
    "            # 生産日のデータを日付に変換\n",
    "            df[\"ProductionDate\"] = df[\"ProductionDate\"].apply(get_datetime)\n",
    "            key_name = \"2-\" + str(idx)\n",
    "            # 今回読み込み時の最終行を取得\n",
    "            latest_last_row = df.shape[0]\n",
    "            # 前回時の最終行を読み込み\n",
    "            last_time_last_row = dict_for_this_month[key_name]\n",
    "            # 新たにデータが追加されていた場合のみdictの書き換えとDFの読み込みを行う\n",
    "            if latest_last_row != last_time_last_row:\n",
    "                dict_for_this_month[key_name] = latest_last_row\n",
    "                # 前回更新時最終行から取得\n",
    "                df = df.iloc[last_time_last_row:, :]\n",
    "                df_list.append(df)\n",
    "    elif \"3号機\" in file:\n",
    "        df = pd.read_excel(file, sheet_name='1-3', names=df_header, header=12, usecols=range(0, 61))\n",
    "        # NaN -> 0\n",
    "        df.fillna(0, inplace=True)\n",
    "        # dummy列の削除\n",
    "        df.drop(['dummy'], axis=1, inplace=True)\n",
    "        # データのある行のみを抽出\n",
    "        df = df[df['ActualThickness(WS)'] != 0]\n",
    "        # 生産日のデータを日付に変換\n",
    "        df[\"ProductionDate\"] = df[\"ProductionDate\"].apply(get_datetime)\n",
    "        key_name = \"1-3-\" + str(idx_for_1_3)\n",
    "        # 今回読み込み時の最終行を取得\n",
    "        latest_last_row = df.shape[0]\n",
    "        # 前回時の最終行を読み込み\n",
    "        last_time_last_row = dict_for_this_month[key_name]\n",
    "        # 新たにデータが追加されていた場合のみdictの書き換えとDFの読み込みを行う\n",
    "        if latest_last_row != last_time_last_row:\n",
    "            dict_for_this_month[key_name] = latest_last_row\n",
    "            # 前回更新時最終行から取得\n",
    "            df = df.iloc[last_time_last_row:, :]\n",
    "            df_list.append(df)\n",
    "        idx_for_1_3 += 1\n",
    "\n",
    "\n",
    "# 各ファイルの最終行を記録したdictをシリアライズ\n",
    "with open('row_num_this_month.pickle', 'wb') as f:\n",
    "    pickle.dump(dict_for_this_month, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8280c0e0-a4eb-4d09-9d20-7ab2d681a2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 更新されたDFが1つだけの場合はそのまま取り出す\n",
    "if len(df_list) == 1:\n",
    "    df_upload = df_list[0]\n",
    "elif len(df_list) == 0:\n",
    "    df_uploat = None\n",
    "# 複数ある場合はUnion\n",
    "else:\n",
    "    df_upload = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bc5c1bc-9cc8-4d02-acf6-63ed77cce386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBにデータをアップロード(今月分・170m以上)\n",
    "# 更新されたデータがあった場合のみDBにアップロード\n",
    "if len(df_upload):\n",
    "    upload_data(insert_data_sql, df_upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161b626f-8a86-40bc-af61-0377b7dbd0b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caf8642-ff81-43a8-8cdd-1783e3db4a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "723ab443-9a6d-401e-9229-d9e1cda11e14",
   "metadata": {},
   "source": [
    "# 170万メートル未満のデータ処理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0c20db-f876-44ba-a96e-2f535046ed42",
   "metadata": {},
   "source": [
    "### 各ファイルのデータをDFに読み込む (前月分)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a726a2e7-21c7-45eb-8753-fed7050f6a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "# 各ファイルのシート毎にDFを作成\n",
    "\n",
    "# '3号機'ファイル用にインデックスを準備\n",
    "idx_for_1_3 = 1\n",
    "\n",
    "if data_file_last_month_lt_170:\n",
    "    for file in data_files_last_month_lt_170:\n",
    "\n",
    "        if \"1期正極\" in file:\n",
    "\n",
    "            # 行番号をシリアライズするためにenumerate()のインデックスを利用\n",
    "            for idx, sheet_name in enumerate(sheet_name_1, start=1):\n",
    "                df = pd.read_excel(file, sheet_name=sheet_name, names=df_header, header=12, usecols=range(0, 61))\n",
    "                # NaN -> 0\n",
    "                df.fillna(0, inplace=True)\n",
    "                # dummy列の削除\n",
    "                df.drop(['dummy'], axis=1, inplace=True)\n",
    "                # データのある行のみを抽出\n",
    "                df = df[df['ActualThickness(WS)'] != 0]\n",
    "                # 生産日のデータを日付に変換\n",
    "                df[\"ProductionDate\"] = df[\"ProductionDate\"].apply(get_datetime)\n",
    "                key_name = \"1-\" + str(idx)\n",
    "                # 今回読み込み時の最終行を取得\n",
    "                latest_last_row = df.shape[0]\n",
    "                # 前回時の最終行を読み込み\n",
    "                last_time_last_row = dict_for_last_month_lt170[key_name]\n",
    "                # 新たにデータが追加されていた場合のみdictの書き換えとDFの読み込みを行う\n",
    "                if latest_last_row != last_time_last_row:\n",
    "                    dict_for_last_month_lt170[key_name] = latest_last_row\n",
    "                    # 前回更新時の最終行から取得\n",
    "                    df = df.iloc[last_time_last_row:, :]\n",
    "                    df_list.append(df)\n",
    "        elif \"2期正極\" in file:\n",
    "            # 行番号をシリアライズするためにenumerate()のインデックスを利用\n",
    "            for idx, sheet_name in enumerate(sheet_name_2, start=1):\n",
    "                df = pd.read_excel(file, sheet_name=sheet_name, names=df_header, header=12, usecols=range(0, 61))\n",
    "                # NaN -> 0\n",
    "                df.fillna(0, inplace=True)\n",
    "                # dummy列の削除\n",
    "                df.drop(['dummy'], axis=1, inplace=True)\n",
    "                # データのある行のみを抽出\n",
    "                df = df[df['ActualThickness(WS)'] != 0]\n",
    "                # 生産日のデータを日付に変換\n",
    "                df[\"ProductionDate\"] = df[\"ProductionDate\"].apply(get_datetime)\n",
    "                key_name = \"2-\" + str(idx)\n",
    "                # 今回読み込み時の最終行を取得\n",
    "                latest_last_row = df.shape[0]\n",
    "                # 前回時の最終行を読み込み\n",
    "                last_time_last_row = dict_for_last_month_lt170[key_name]\n",
    "                # 新たにデータが追加されていた場合のみdictの書き換えとDFの読み込みを行う\n",
    "                if latest_last_row != last_time_last_row:\n",
    "                    dict_for_last_month_lt170[key_name] = latest_last_row\n",
    "                    # 前回更新時最終行から取得\n",
    "                    df = df.iloc[last_time_last_row:, :]\n",
    "                    df_list.append(df)\n",
    "        elif \"3号機\" in file:\n",
    "            df = pd.read_excel(file, sheet_name='1-3', names=df_header, header=12, usecols=range(0, 61))\n",
    "            # NaN -> 0\n",
    "            df.fillna(0, inplace=True)\n",
    "            # dummy列の削除\n",
    "            df.drop(['dummy'], axis=1, inplace=True)\n",
    "            # データのある行のみを抽出\n",
    "            df = df[df['ActualThickness(WS)'] != 0]\n",
    "            # 生産日のデータを日付に変換\n",
    "            df[\"ProductionDate\"] = df[\"ProductionDate\"].apply(get_datetime)\n",
    "            key_name = \"1-3-\" + str(idx_for_1_3)\n",
    "            # 今回読み込み時の最終行を取得\n",
    "            latest_last_row = df.shape[0]\n",
    "            # 前回時の最終行を読み込み\n",
    "            last_time_last_row = dict_for_last_month_lt170[key_name]\n",
    "            # 新たにデータが追加されていた場合のみdictの書き換えとDFの読み込みを行う\n",
    "            if latest_last_row != last_time_last_row:\n",
    "                dict_for_last_month_lt170[key_name] = latest_last_row\n",
    "                # 前回更新時最終行から取得\n",
    "                df = df.iloc[last_time_last_row:, :]\n",
    "                df_list.append(df)\n",
    "            idx_for_1_3 += 1\n",
    "        \n",
    "\n",
    "# 各ファイルの最終行を記録したdictをシリアライズ\n",
    "with open('row_num_last_month.pickle', 'wb') as f:\n",
    "    pickle.dump(dict_for_last_month_lt170, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42b5694-6f99-4c00-9a92-efb510dc46cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 更新されたDFが1つだけの場合はそのまま取り出す\n",
    "if len(df_list) == 1:\n",
    "    df_upload = df_list[0]\n",
    "elif len(df_list) == 0:\n",
    "    df_upload = None\n",
    "# 複数ある場合はUnion\n",
    "else:\n",
    "    df_upload = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c433f68-0c3f-48bd-91bf-302297681b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBにデータをアップロード\n",
    "# 更新されたデータがあった場合のみDBにアップロード\n",
    "if len(df_upload):\n",
    "    upload_data(insert_data_sql_lt170, df_upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d34ea8-3020-4143-ba78-4e3204413621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0af8d0-6710-4f60-84ae-e345ea8cea8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0553def-f177-4c48-8f40-409b75787590",
   "metadata": {},
   "source": [
    "### 各ファイルのデータをDFに読み込む (今月分)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e3acb0e-0df7-4b99-9b83-19c1df774575",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "# 各ファイルのシート毎にDFを作成\n",
    "\n",
    "# '3号機'ファイル用にインデックスを準備\n",
    "idx_for_1_3 = 1\n",
    "\n",
    "if data_files_this_month_lt_170:\n",
    "    for file in data_files_this_month_lt_170:\n",
    "\n",
    "        if \"1期正極\" in file:\n",
    "\n",
    "            # 行番号をシリアライズするためにenumerate()のインデックスを利用\n",
    "            for idx, sheet_name in enumerate(sheet_name_1, start=1):\n",
    "                df = pd.read_excel(file, sheet_name=sheet_name, names=df_header, header=12, usecols=range(0, 61))\n",
    "                # NaN -> 0\n",
    "                df.fillna(0, inplace=True)\n",
    "                # dummy列の削除\n",
    "                df.drop(['dummy'], axis=1, inplace=True)\n",
    "                # データのある行のみを抽出\n",
    "                df = df[df['ActualThickness(WS)'] != 0]\n",
    "                # 生産日のデータを日付に変換\n",
    "                df[\"ProductionDate\"] = df[\"ProductionDate\"].apply(get_datetime)\n",
    "                key_name = \"1-\" + str(idx)\n",
    "                # 今回読み込み時の最終行を取得\n",
    "                latest_last_row = df.shape[0]\n",
    "                # 前回時の最終行を読み込み\n",
    "                last_time_last_row = dict_for_this_month_lt170[key_name]\n",
    "                # 新たにデータが追加されていた場合のみdictの書き換えとDFの読み込みを行う\n",
    "                if latest_last_row != last_time_last_row:\n",
    "                    dict_for_this_month_lt170[key_name] = latest_last_row\n",
    "                    # 前回更新時の最終行から取得\n",
    "                    df = df.iloc[last_time_last_row:, :]\n",
    "                    df_list.append(df)\n",
    "        elif \"2期正極\" in file:\n",
    "            # 行番号をシリアライズするためにenumerate()のインデックスを利用\n",
    "            for idx, sheet_name in enumerate(sheet_name_2, start=1):\n",
    "                df = pd.read_excel(file, sheet_name=sheet_name, names=df_header, header=12, usecols=range(0, 61))\n",
    "                # NaN -> 0\n",
    "                df.fillna(0, inplace=True)\n",
    "                # dummy列の削除\n",
    "                df.drop(['dummy'], axis=1, inplace=True)\n",
    "                # データのある行のみを抽出\n",
    "                df = df[df['ActualThickness(WS)'] != 0]\n",
    "                # 生産日のデータを日付に変換\n",
    "                df[\"ProductionDate\"] = df[\"ProductionDate\"].apply(get_datetime)\n",
    "                key_name = \"2-\" + str(idx)\n",
    "                # 今回読み込み時の最終行を取得\n",
    "                latest_last_row = df.shape[0]\n",
    "                # 前回時の最終行を読み込み\n",
    "                last_time_last_row = dict_for_this_month_lt170[key_name]\n",
    "                # 新たにデータが追加されていた場合のみdictの書き換えとDFの読み込みを行う\n",
    "                if latest_last_row != last_time_last_row:\n",
    "                    dict_for_this_month_lt170[key_name] = latest_last_row\n",
    "                    # 前回更新時最終行から取得\n",
    "                    df = df.iloc[last_time_last_row:, :]\n",
    "                    df_list.append(df)\n",
    "        elif \"3号機\" in file:\n",
    "            df = pd.read_excel(file, sheet_name='1-3', names=df_header, header=12, usecols=range(0, 61))\n",
    "            # NaN -> 0\n",
    "            df.fillna(0, inplace=True)\n",
    "            # dummy列の削除\n",
    "            df.drop(['dummy'], axis=1, inplace=True)\n",
    "            # データのある行のみを抽出\n",
    "            df = df[df['ActualThickness(WS)'] != 0]\n",
    "            # 生産日のデータを日付に変換\n",
    "            df[\"ProductionDate\"] = df[\"ProductionDate\"].apply(get_datetime)\n",
    "            key_name = \"1-3-\" + str(idx_for_1_3)\n",
    "            # 今回読み込み時の最終行を取得\n",
    "            latest_last_row = df.shape[0]\n",
    "            # 前回時の最終行を読み込み\n",
    "            last_time_last_row = dict_for_this_month_lt170[key_name]\n",
    "            # 新たにデータが追加されていた場合のみdictの書き換えとDFの読み込みを行う\n",
    "            if latest_last_row != last_time_last_row:\n",
    "                dict_for_this_month_lt170[key_name] = latest_last_row\n",
    "                # 前回更新時最終行から取得\n",
    "                df = df.iloc[last_time_last_row:, :]\n",
    "                df_list.append(df)\n",
    "            idx_for_1_3 += 1\n",
    "\n",
    "\n",
    "# 各ファイルの最終行を記録したdictをシリアライズ\n",
    "with open('row_num_this_month.pickle', 'wb') as f:\n",
    "    pickle.dump(dict_for_this_month_lt170, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e43c41-bdf8-4c5c-bcec-312c89f94221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 更新されたDFが1つだけの場合はそのまま取り出す\n",
    "if len(df_list) == 1:\n",
    "    df_upload = df_list[0]\n",
    "elif len(df_list) == 0:\n",
    "    df_upload = 0\n",
    "# 複数ある場合はUnion\n",
    "else:\n",
    "    df_upload = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a89c834f-331f-4615-85da-9b18ce33f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBにデータをアップロード\n",
    "# 更新されたデータがあった場合のみDBにアップロード\n",
    "if len(df_upload):\n",
    "    upload_data(insert_data_sql_lt170, df_upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d17a8bd-6dfd-46b2-8598-98e3da72dcd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c96a6b-e7c3-4a90-bca7-9f8ecb0e1559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f82103c-20db-4aee-96f5-1149ec3bf7f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca974ea-e82c-4d7f-a431-39b63c92ccbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726541d5-bcc2-4e4a-a9cd-e233a43f7d15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486f4193-8d33-470f-b43d-0c4a38ba9159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
